apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: longhorn
  namespace: longhorn-system
spec:
  interval: 30m
  chart:
    spec:
      chart: longhorn
      version: 1.10.1  # Latest stable (Nov 2024) - includes Talos bug fixes
      sourceRef:
        kind: HelmRepository
        name: longhorn
        namespace: longhorn-system
      interval: 12h
  install:
    remediation:
      retries: 3
    createNamespace: false  # We create namespace separately
    timeout: 20m  # Increase timeout for slower clusters
  upgrade:
    remediation:
      retries: 3
    timeout: 20m  # Increase timeout for slower clusters
  values:
    # Talos-specific settings
    defaultSettings:
      # Set default replica count (2 workers = 2 replicas)
      defaultReplicaCount: 2

      # Talos uses /var/mnt/longhorn as mount point (configured in Omni)
      defaultDataPath: /var/mnt/longhorn

      # Guaranteed engine CPU for performance (percentage: 12 = 12%)
      guaranteedEngineManagerCPU: 12
      guaranteedReplicaManagerCPU: 12

      # Auto-balance replicas across nodes for better distribution
      replicaAutoBalance: best-effort

      # Faster volume deletion (safe with Retain reclaim policy)
      nodeDownPodDeletionPolicy: delete-both-statefulset-and-deployment-pod

    # Persistence settings
    persistence:
      defaultClass: true  # Make Longhorn the default StorageClass
      defaultClassReplicaCount: 2  # Match defaultReplicaCount
      reclaimPolicy: Retain  # Keep data if PVC is deleted (safer)

    # Enable Longhorn UI
    ingress:
      enabled: false  # Set to true if you want to expose via ingress
      # host: longhorn.yourdomain.com
      # annotations:
      #   cert-manager.io/cluster-issuer: letsencrypt-prod

    # Service configuration for UI
    service:
      ui:
        # type: ClusterIP  # Use ClusterIP, access via port-forward or ingress
        type: LoadBalancer  # Uncomment to expose via MetalLB

    # Tolerations for control-plane nodes (if you want to use them)
    # longhornManager:
    #   tolerations:
    #     - key: node-role.kubernetes.io/control-plane
    #       operator: Exists
    #       effect: NoSchedule

    # Resource limits (adjust based on your cluster size)
    longhornManager:
      resources:
        requests:
          cpu: 100m
          memory: 128Mi
        limits:
          cpu: 1000m
          memory: 512Mi

    longhornDriver:
      resources:
        requests:
          cpu: 10m
          memory: 32Mi
        limits:
          cpu: 100m
          memory: 128Mi

    longhornUI:
      resources:
        requests:
          cpu: 10m
          memory: 32Mi
        limits:
          cpu: 100m
          memory: 128Mi
